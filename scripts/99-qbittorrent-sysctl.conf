# Kernel network stack tuning for qBittorrent optimization
# Place in /etc/sysctl.d/99-qbittorrent.conf and run: sudo sysctl -p /etc/sysctl.d/99-qbittorrent.conf

# ═══════════════════════════════════════════════════════════════════════════
# TCP BUFFER SIZES - Critical for high-bandwidth torrenting
# ═══════════════════════════════════════════════════════════════════════════
# Increase buffer sizes to handle 2000 concurrent connections
net.core.rmem_max = 134217728
net.core.wmem_max = 134217728
net.core.rmem_default = 262144
net.core.wmem_default = 262144

# TCP auto-tuning: min, default, max (in bytes)
# 128 MB max allows high throughput without manual tuning per socket
net.ipv4.tcp_rmem = 4096 87380 134217728
net.ipv4.tcp_wmem = 4096 65536 134217728

# ═══════════════════════════════════════════════════════════════════════════
# CONNECTION TRACKING - Handle high peer count
# ═══════════════════════════════════════════════════════════════════════════
net.core.netdev_max_backlog = 5000
net.core.somaxconn = 4096
net.ipv4.tcp_max_syn_backlog = 8192

# netdev backlog: queue incoming packets when CPU is busy
# somaxconn: listen() queue size for WebUI + tracker connections
# syn_backlog: handle connection bursts during peer discovery

# ═══════════════════════════════════════════════════════════════════════════
# TCP PERFORMANCE - Optimize for bulk data transfer
# ═══════════════════════════════════════════════════════════════════════════
net.ipv4.tcp_window_scaling = 1
net.ipv4.tcp_timestamps = 1
net.ipv4.tcp_sack = 1
net.ipv4.tcp_fack = 1
net.ipv4.tcp_low_latency = 0

# Window scaling: essential for high bandwidth-delay product
# Timestamps: better RTT estimation
# SACK/FACK: selective ACK for faster recovery from packet loss
# Low latency: 0 = throughput priority (we want bulk transfer, not gaming)

# ═══════════════════════════════════════════════════════════════════════════
# TCP CONGESTION CONTROL
# ═══════════════════════════════════════════════════════════════════════════
net.ipv4.tcp_congestion_control = bbr
net.core.default_qdisc = fq

# BBR: Bottleneck Bandwidth & RTT - best for bulk transfers
# fq: Fair Queue - works well with BBR
# Alternative if BBR unavailable: cubic (Linux default)

# ═══════════════════════════════════════════════════════════════════════════
# CONNECTION REUSE - Faster peer reconnection
# ═══════════════════════════════════════════════════════════════════════════
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 15

# TIME_WAIT reuse: recycle closed sockets faster (safe for NAT)
# FIN timeout: 15s (down from 60s) - free resources quicker

# ═══════════════════════════════════════════════════════════════════════════
# MEMORY PRESSURE - Prevent OOM on high connection count
# ═══════════════════════════════════════════════════════════════════════════
net.ipv4.tcp_moderate_rcvbuf = 1
net.ipv4.tcp_no_metrics_save = 1

# Moderate rcvbuf: auto-tune receive buffer (don't over-allocate)
# No metrics save: don't cache per-peer metrics (saves RAM with 2000 peers)

# ═══════════════════════════════════════════════════════════════════════════
# IPv6 (disable if not used to reduce overhead)
# ═══════════════════════════════════════════════════════════════════════════
# net.ipv6.conf.all.disable_ipv6 = 1
# net.ipv6.conf.default.disable_ipv6 = 1

# Uncomment if you don't use IPv6 - saves memory and CPU cycles

# ═══════════════════════════════════════════════════════════════════════════
# FILE DESCRIPTOR LIMITS
# ═══════════════════════════════════════════════════════════════════════════
fs.file-max = 100000

# System-wide file descriptor limit - needed for 2000 connections + disk I/O
# Also ensure Docker ulimits are set (already done in docker-compose.yml)
